{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65fbd664",
   "metadata": {},
   "source": [
    "# Pre-processing and Training\n",
    "in this project I'm completing step 4 of my capstone project where I need to:\n",
    "\n",
    "Create dummy or indicator features for categorical variables\n",
    "\n",
    "Standardize the magnitude of numeric features using a scaler\n",
    "\n",
    "Split your data into testing and training datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d992ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a530bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'/Users/carlriemann/Documents/GitHub/Capstone-Two-EDA/EDA project1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bbb6992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2851, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f6caa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Player', 'Age', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA',\n",
      "       '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB',\n",
      "       'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Tm', 'Season', 'Pos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992417b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player     object\n",
      "Age         int64\n",
      "G           int64\n",
      "GS          int64\n",
      "MP        float64\n",
      "FG        float64\n",
      "FGA       float64\n",
      "FG%       float64\n",
      "3P        float64\n",
      "3PA       float64\n",
      "3P%       float64\n",
      "2P        float64\n",
      "2PA       float64\n",
      "2P%       float64\n",
      "eFG%      float64\n",
      "FT        float64\n",
      "FTA       float64\n",
      "FT%       float64\n",
      "ORB       float64\n",
      "DRB       float64\n",
      "TRB       float64\n",
      "AST       float64\n",
      "STL       float64\n",
      "BLK       float64\n",
      "TOV       float64\n",
      "PF        float64\n",
      "PTS       float64\n",
      "Tm         object\n",
      "Season     object\n",
      "Pos        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3879173",
   "metadata": {},
   "source": [
    "The main goal of this step is to clean, transform, and split the data so that it is ready for training machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd31f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell i perform more data cleaning in order to have it ready for training.\n",
    "#changing 'unknown' position to the most common position (I decided to replace these Unknown values with the most common position in the dataset)\n",
    "most_common_pos = df['Pos'].mode()[0]\n",
    "df['Pos'] = df['Pos'].replace('Unknown', most_common_pos)\n",
    "#Dropping Player column as it is unique\n",
    "df = df.drop(columns=['Player'])\n",
    "#Turn season column to contain only the starting year of the season (this ensured I don't encounter errors when testing the model)\n",
    "df['Season'] = df['Season'].apply(lambda x: int(x.split('-')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad422f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy variables\n",
    "df = pd.get_dummies(df, columns=['Tm', 'Pos'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f6cd5",
   "metadata": {},
   "source": [
    "I identified the Tm (Team) and Pos (Position) columns as categorical features in my dataset.\n",
    "To include these features in the model, I convert them to dummy/indicator variables using pd.get_dummies(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a41b2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select numerical columns and scale them\n",
    "numerical_columns = ['Age', 'G', 'GS', 'MP', 'FG', 'FGA', '3P', '3PA', '2P', '2PA', 'FT', 'FTA', \n",
    "                     'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "#Standarizing the numerical features using StandardScaler. This ensured that all features have a mean of 0 and a standard deviation of 1.\n",
    "scaler = StandardScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "#Define target variable\n",
    "X = df.drop(columns=['PTS'])\n",
    "y = df['PTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60fea5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b285a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.00011804687556539186\n",
      "R-squared: 0.999887617886216\n"
     ]
    }
   ],
   "source": [
    "#test linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "#check metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b47ff",
   "metadata": {},
   "source": [
    "I trained a Linear Regression model on the preprocessed data.\n",
    "The model achieved a Mean Squared Error (MSE) of 0.000118 and an R-squared value of 0.9999 on the test set, indicating a high level of accuracy in predicting points per game (PTS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c775cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
